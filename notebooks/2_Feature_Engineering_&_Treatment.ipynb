{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "pd.set_option(\"display.max_rows\", 80)\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Helper functions\n",
    "from helper_functions import handle_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will contain **data preprocessing steps** before building a machine learning model for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3700 entries, 0 to 3699\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   v1          3661 non-null   object \n",
      " 1   v2          3661 non-null   float64\n",
      " 2   v3          3700 non-null   float64\n",
      " 3   v4          3636 non-null   object \n",
      " 4   v5          3700 non-null   float64\n",
      " 5   v6          3700 non-null   float64\n",
      " 6   v7          3700 non-null   float64\n",
      " 7   v8          3700 non-null   object \n",
      " 8   v9          3700 non-null   object \n",
      " 9   v10         3700 non-null   int64  \n",
      " 10  v11         3700 non-null   object \n",
      " 11  v12         3700 non-null   object \n",
      " 12  v13         3600 non-null   float64\n",
      " 13  v14         3700 non-null   int64  \n",
      " 14  v15         3600 non-null   float64\n",
      " 15  v16         1555 non-null   object \n",
      " 16  v17         3700 non-null   int64  \n",
      " 17  classLabel  3700 non-null   object \n",
      "dtypes: float64(7), int64(3), object(8)\n",
      "memory usage: 520.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/training2.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   v1          197 non-null    object \n",
      " 1   v2          197 non-null    float64\n",
      " 2   v3          200 non-null    float64\n",
      " 3   v4          198 non-null    object \n",
      " 4   v5          200 non-null    float64\n",
      " 5   v6          200 non-null    float64\n",
      " 6   v7          200 non-null    float64\n",
      " 7   v8          200 non-null    object \n",
      " 8   v9          200 non-null    object \n",
      " 9   v10         200 non-null    int64  \n",
      " 10  v11         200 non-null    object \n",
      " 11  v12         200 non-null    object \n",
      " 12  v13         197 non-null    float64\n",
      " 13  v14         200 non-null    int64  \n",
      " 14  v15         197 non-null    float64\n",
      " 15  v16         89 non-null     object \n",
      " 16  v17         200 non-null    int64  \n",
      " 17  classLabel  200 non-null    object \n",
      "dtypes: float64(7), int64(3), object(8)\n",
      "memory usage: 28.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.read_csv('../data/validation2.csv')\n",
    "df_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.0 Dropping problematic columns**\n",
    "\n",
    "**More than half of the rows in feature** `v16` **are missing** in both `df_train` & `df_val`. Using imputation techniques may not be the best approach because imputing missing values in a categorical variable with such a high rate of missing data can introduce bias and distort the original distribution. Hence, **we'll be dropping this column from both datasets**.\n",
    "\n",
    "We've also identified that **columns** `v13` **&** `v15` **are perfectly correlated with each other**. Hence, we'll randomly drop one of them. In this case, we'll also drop `v15`. Should information on these features be available, we may reconsider this.\n",
    "\n",
    "`v17` is also dropped due to having suspiciously high correlation with the target, `classLabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['v16', 'v15', 'v17'], inplace=True, axis='columns')\n",
    "df_val.drop(['v16', 'v15', 'v17'], inplace=True, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.0 Impute missing values**\n",
    "\n",
    "The rest of the features have a smaller portion of missing values.\n",
    "\n",
    "For numerical columns (`v2`, `v13` & `v15`), I will impute the missing values with the median value as the median is less impacted by outliers compared to the mean since most of the numerical columns are positively skewed with outliers.\n",
    "\n",
    "For categorical columns (`v1` & `v4`), I will impute the missing category by labelling the missing value with their respective modes. This is due to both columns having clear modes and imputing with the mode helps maintain the original distribution of the categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1           1.054\n",
      "v2           1.054\n",
      "v3           0.000\n",
      "v4           1.730\n",
      "v5           0.000\n",
      "v6           0.000\n",
      "v7           0.000\n",
      "v8           0.000\n",
      "v9           0.000\n",
      "v10          0.000\n",
      "v11          0.000\n",
      "v12          0.000\n",
      "v13          2.703\n",
      "v14          0.000\n",
      "classLabel   0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage_df_train = df_train.isnull().sum() * 100/len(df_train)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(missing_percentage_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1           1.500\n",
      "v2           1.500\n",
      "v3           0.000\n",
      "v4           1.000\n",
      "v5           0.000\n",
      "v6           0.000\n",
      "v7           0.000\n",
      "v8           0.000\n",
      "v9           0.000\n",
      "v10          0.000\n",
      "v11          0.000\n",
      "v12          0.000\n",
      "v13          1.500\n",
      "v14          0.000\n",
      "classLabel   0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage_df_val = df_val.isnull().sum() * 100/len(df_val)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(missing_percentage_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate categorical & numerical columns for analyses\n",
    "CatCols=['v1', 'v4', 'v8', 'v9', 'v11',\n",
    "         'v12', 'classLabel']\n",
    "NumCols=list(set(df_train.columns)-set(CatCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute using the helper function we imported at the start\n",
    "df_train2 = handle_missing_values(df_train, categorical_cols=CatCols, numerical_cols=NumCols)\n",
    "df_val2 = handle_missing_values(df_val, categorical_cols=CatCols, numerical_cols=NumCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3700 entries, 0 to 3699\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   v1          3700 non-null   category\n",
      " 1   v2          3700 non-null   float64 \n",
      " 2   v3          3700 non-null   float64 \n",
      " 3   v4          3700 non-null   category\n",
      " 4   v5          3700 non-null   float64 \n",
      " 5   v6          3700 non-null   float64 \n",
      " 6   v7          3700 non-null   float64 \n",
      " 7   v8          3700 non-null   category\n",
      " 8   v9          3700 non-null   category\n",
      " 9   v10         3700 non-null   int64   \n",
      " 10  v11         3700 non-null   category\n",
      " 11  v12         3700 non-null   category\n",
      " 12  v13         3700 non-null   float64 \n",
      " 13  v14         3700 non-null   int64   \n",
      " 14  classLabel  3700 non-null   category\n",
      "dtypes: category(7), float64(6), int64(2)\n",
      "memory usage: 257.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   v1          200 non-null    category\n",
      " 1   v2          200 non-null    float64 \n",
      " 2   v3          200 non-null    float64 \n",
      " 3   v4          200 non-null    category\n",
      " 4   v5          200 non-null    float64 \n",
      " 5   v6          200 non-null    float64 \n",
      " 6   v7          200 non-null    float64 \n",
      " 7   v8          200 non-null    category\n",
      " 8   v9          200 non-null    category\n",
      " 9   v10         200 non-null    int64   \n",
      " 10  v11         200 non-null    category\n",
      " 11  v12         200 non-null    category\n",
      " 12  v13         200 non-null    float64 \n",
      " 13  v14         200 non-null    int64   \n",
      " 14  classLabel  200 non-null    category\n",
      "dtypes: category(7), float64(6), int64(2)\n",
      "memory usage: 14.9 KB\n"
     ]
    }
   ],
   "source": [
    "# final check\n",
    "df_val2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.0 Binning categorical columns with high cardinality**\n",
    "\n",
    "As previously identified, **different values for** `v4` **(l) and** `v12` **(o) have very small occurences in the dataset (<1%)**. Hence, we will use binning (where a smaller variable is subsumed into a larger variable) to reduce the feature's cardinality.\n",
    "\n",
    "However, since I am not privy to the real-world nature of each feature, I will subsume the smallest occuring value in the non-largest occuring value e.g., *l* in `v4` will be subsumed into `y` instead of `u`. We ought to consider domain specific knowledge of course should it be available in the future.\n",
    "\n",
    "I'd like to also note that value *p* in `v12` is especially sparse (<2%). While an argument can be made to bin it as well, I will leave it be for now due to the lack of domain knowledge (since *p*'s sparsity may be justified in real life!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries to remap values in columns v4 & v12\n",
    "bin_v4 = {\n",
    "    'u': 'u',\n",
    "    'y': 'y',\n",
    "    'l': 'y',\n",
    "}\n",
    "\n",
    "bin_v12 = {\n",
    "    'g': 'g',\n",
    "    's': 's',\n",
    "    'p': 'p',\n",
    "    'o': 'p',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in v4 before binning: ['u', 'y', 'l']\n",
      "Categories (3, object): ['l', 'u', 'y']\n",
      "\n",
      "Unique values in v4 after binning: ['u', 'y']\n",
      "Categories (2, object): ['u', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique values in v4 before binning: {df_train2.v4.unique()}\")\n",
    "print(\"\")\n",
    "\n",
    "df_train2.v4.replace(bin_v4, inplace=True)\n",
    "\n",
    "print(f\"Unique values in v4 after binning: {df_train2.v4.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in v12 before binning: ['s', 'g', 'p', 'o']\n",
      "Categories (4, object): ['g', 'o', 'p', 's']\n",
      "\n",
      "Unique values in v12 after binning: ['s', 'g', 'p']\n",
      "Categories (3, object): ['g', 'p', 's']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique values in v12 before binning: {df_val2.v12.unique()}\")\n",
    "print(\"\")\n",
    "\n",
    "df_val2.v12.replace(bin_v12, inplace=True)\n",
    "\n",
    "print(f\"Unique values in v12 after binning: {df_val2.v12.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.0 One-Hot encoding categorical columns**\n",
    "\n",
    "Next I will transform the categorical features to one-hot-encoded features. This is because a logistic regression model (our choice for a baseline) can only take in numeric input. An argument can be made for label encoding but we do not know if there's an ordinal structure for any of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of categorical columns:\n",
      "['v1', 'v4', 'v8', 'v9', 'v11', 'v12', 'classLabel']\n",
      "\n",
      "List of numerical columns:\n",
      "['v10', 'v2', 'v7', 'v13', 'v14', 'v6', 'v5', 'v3']\n"
     ]
    }
   ],
   "source": [
    "print(f\"List of categorical columns:\\n{CatCols}\")\n",
    "print(\"\")\n",
    "print(f\"List of numerical columns:\\n{NumCols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of categories in categorical features: 3\n"
     ]
    }
   ],
   "source": [
    "max_number_of_categories = max([df_train2[col].nunique() for col in CatCols])\n",
    "print(f\"Max number of categories in categorical features: {max_number_of_categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v4_y</th>\n",
       "      <th>v8_t</th>\n",
       "      <th>v9_t</th>\n",
       "      <th>v11_t</th>\n",
       "      <th>v12_p</th>\n",
       "      <th>v12_s</th>\n",
       "      <th>classLabel_yes.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>0.523</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>80.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.160</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0</td>\n",
       "      <td>200.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.751</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>96.000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v2    v3     v5    v6    v7  v10     v13  v14  v1_b  v4_y  v8_t  v9_t  \\\n",
       "0 17.920 0.000 -0.840 0.523 1.750    1  80.000    5     0     0     0     1   \n",
       "1 16.920 0.000 -2.160 0.774 0.290    0 200.000    0     1     1     0     0   \n",
       "2 31.250 0.000  1.751 0.760 0.000    1  96.000   19     1     0     0     1   \n",
       "\n",
       "   v11_t  v12_p  v12_s  classLabel_yes.  \n",
       "0      1      0      0                0  \n",
       "1      0      0      1                0  \n",
       "2      0      0      0                0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2 = pd.get_dummies(\n",
    "    df_train2,\n",
    "    columns=CatCols,\n",
    "    dtype=int,\n",
    "    drop_first=True # to avoid multi-collinearity\n",
    ")\n",
    "df_train2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v4_y</th>\n",
       "      <th>v8_t</th>\n",
       "      <th>v9_t</th>\n",
       "      <th>v11_t</th>\n",
       "      <th>v12_p</th>\n",
       "      <th>v12_s</th>\n",
       "      <th>classLabel_yes.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.330</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.545</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>420.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.174</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0</td>\n",
       "      <td>136.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.232</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0</td>\n",
       "      <td>240.000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v2    v3     v5    v6    v7  v10     v13  v14  v1_b  v4_y  v8_t  v9_t  \\\n",
       "0 32.330 0.001  0.840 0.545 1.585    0 420.000    0     1     0     1     0   \n",
       "1 23.580 0.000 -4.174 0.864 0.540    0 136.000    1     1     0     0     0   \n",
       "2 36.420 0.000  2.232 0.627 0.585    0 240.000    3     1     1     0     0   \n",
       "\n",
       "   v11_t  v12_p  v12_s  classLabel_yes.  \n",
       "0      1      0      1                0  \n",
       "1      1      0      0                0  \n",
       "2      0      0      0                0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val2 = pd.get_dummies(\n",
    "    df_val2,\n",
    "    columns=CatCols,\n",
    "    dtype=int,\n",
    "    drop_first=True # to avoid multi-collinearity\n",
    ")\n",
    "df_val2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.0 Scaling on numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v10', 'v2', 'v7', 'v13', 'v14', 'v6', 'v5', 'v3']\n"
     ]
    }
   ],
   "source": [
    "print(NumCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our choice of scaler is the `RobustScaler()`. This scaler is used to scale features while taking into account the presence of outliers in your data. It scales the features to be centered around the median and within a certain interquartile range, which makes it robust to the influence of outliers. This is especially the case since most of our numerical features are positively skewed. \n",
    "\n",
    "However, it is important to note that **features** `v5` **&** `v6` **are not skewed positively**. Hence, later iterations can explore different scaling methods on them e.g., MinMax Scaler, Standard Scaler, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "df_train2[NumCols] = scaler.fit_transform(df_train2[NumCols])\n",
    "df_val2[NumCols] = scaler.fit_transform(df_val2[NumCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v4_y</th>\n",
       "      <th>v8_t</th>\n",
       "      <th>v9_t</th>\n",
       "      <th>v11_t</th>\n",
       "      <th>v12_p</th>\n",
       "      <th>v12_s</th>\n",
       "      <th>classLabel_yes.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-1.448</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.691</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v2     v3     v5     v6     v7    v10    v13    v14  v1_b  v4_y  v8_t  \\\n",
       "0 -0.632 -0.457 -0.160 -1.448  0.000 -0.167 -0.146 -0.102     0     0     0   \n",
       "1 -0.691 -0.482 -0.428 -0.075 -0.324 -0.333  0.292 -0.107     1     1     0   \n",
       "2  0.152 -0.385  0.366 -0.150 -0.389 -0.167 -0.088 -0.089     1     0     0   \n",
       "\n",
       "   v9_t  v11_t  v12_p  v12_s  classLabel_yes.  \n",
       "0     1      1      0      0                0  \n",
       "1     0      0      0      1                0  \n",
       "2     1      0      0      0                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v4_y</th>\n",
       "      <th>v8_t</th>\n",
       "      <th>v9_t</th>\n",
       "      <th>v11_t</th>\n",
       "      <th>v12_p</th>\n",
       "      <th>v12_s</th>\n",
       "      <th>classLabel_yes.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.611</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v2     v3     v5     v6     v7   v10    v13    v14  v1_b  v4_y  v8_t  \\\n",
       "0  0.163  0.728  0.309 -0.600  0.225 0.000  1.300 -0.009     1     0     1   \n",
       "1 -0.372 -0.121 -0.779  0.641 -0.209 0.000 -0.120 -0.007     1     0     0   \n",
       "2  0.413 -0.276  0.611 -0.279 -0.190 0.000  0.400 -0.003     1     1     0   \n",
       "\n",
       "   v9_t  v11_t  v12_p  v12_s  classLabel_yes.  \n",
       "0     0      1      0      1                0  \n",
       "1     0      1      0      0                0  \n",
       "2     0      0      0      0                0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.0 Export cleaned dataset for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2.to_csv(\"../data/processed_training_nov17.csv\", index=False)\n",
    "df_val2.to_csv(\"../data/processed_validation_nov17.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfk_assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
